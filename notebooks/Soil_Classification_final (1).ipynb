{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV9p7V-Yt3Fq",
        "outputId": "574f639f-b4e7-4efe-8883-105cd593bd27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Author: Annam.ai IIT Ropar\n",
        "Team Members: Aman Sagar\n",
        "Leaderboard Rank: 16\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = '/content/drive/My Drive/soil_classification-2025'\n",
        "os.listdir(dataset_path)\n"
      ],
      "metadata": {
        "id": "zIyOcTwEuM3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing: Resize images, normalize pixel values, and apply data augmentation as needed."
      ],
      "metadata": {
        "id": "8IcHzdkix7FZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pandas scikit-learn torchvision\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "wcGkck7Ruyy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
      ],
      "metadata": {
        "id": "G4Fr0XjLmWil",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "484e3421-d249-47f6-a184-030143086407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.3.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torch-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (955.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m955.6/955.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchvision-0.22.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 sympy-1.13.3 torch-2.7.0+cu118 torchaudio-2.7.0+cu118 torchvision-0.22.0+cu118 triton-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"PyTorch version:\", torch.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ7NMxv5dy0-",
        "outputId": "690a7f56-3493-4c0a-de6c-d50e36312ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.7.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ROOT_DIR = \"/content/drive/MyDrive/soil_classification-2025\"\n",
        "TRAIN_CSV = os.path.join(ROOT_DIR, \"train_labels.csv\")\n",
        "TEST_CSV = os.path.join(ROOT_DIR, \"test_ids.csv\")\n",
        "TRAIN_DIR = os.path.join(ROOT_DIR, \"train\")\n",
        "TEST_DIR = os.path.join(ROOT_DIR, \"test\")\n"
      ],
      "metadata": {
        "id": "N__89YJDvpHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\n",
        "    \"Alluvial soil\": 0,\n",
        "    \"Black Soil\": 1,\n",
        "    \"Clay soil\": 2,\n",
        "    \"Red soil\": 3\n",
        "}\n",
        "\n",
        "df = pd.read_csv(TRAIN_CSV)\n",
        "df['label'] = df['soil_type'].map(label_map)\n",
        "# df_train, df_val = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
        "df_train = df  # use the full training set\n"
      ],
      "metadata": {
        "id": "RcdefYYavtOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMAGE_SIZE = 224\n",
        "\n",
        "# train_transforms = transforms.Compose([\n",
        "#     transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.RandomRotation(10),\n",
        "#     transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize([0.485, 0.456, 0.406],  # ImageNet mean\n",
        "#                          [0.229, 0.224, 0.225])  # ImageNet std\n",
        "# ])\n",
        "\n",
        "# val_transforms = transforms.Compose([\n",
        "#     transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize([0.485, 0.456, 0.406],\n",
        "#                          [0.229, 0.224, 0.225])\n",
        "# ])\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.75, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.3),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
        "\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "UtqixVzGvv0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoilDataset(Dataset):\n",
        "    def __init__(self, dataframe, img_dir, transform=None, test=False):\n",
        "        self.df = dataframe\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.test = test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.df.iloc[idx]['image_id']\n",
        "        img_path = os.path.join(self.img_dir, img_id)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.test:\n",
        "            return image, img_id\n",
        "        else:\n",
        "            label = self.df.iloc[idx]['label']\n",
        "            return image, label\n"
      ],
      "metadata": {
        "id": "lgV-uMxawLqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "93PAwB8TmzUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bLXRnREDm233"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AMtFx4FxnAT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r-tWkhjJnCuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzKraTTDnz46",
        "outputId": "58d7c4e1-ed91-4ce3-a017-0b9b097f0756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['image_id', 'soil_type', 'label'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ochvx31nF4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = SoilDataset(df_train, TRAIN_DIR, transform=train_transforms)\n",
        "# val_dataset = SoilDataset(df_val, TRAIN_DIR, transform=val_transforms)\n",
        "val_dataset = SoilDataset(df_val, TRAIN_DIR, transform=val_transforms)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "mkEnCyMPwqWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(TEST_CSV)\n",
        "test_dataset = SoilDataset(test_df, TEST_DIR, transform=val_transforms, test=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "WVyrAxXAwtAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Build Model, Training & Validation Loop\n"
      ],
      "metadata": {
        "id": "ec3r8K6cxrDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm  # nice progress bars\n",
        "\n",
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load pretrained ResNet50 and modify for 4 classes\n",
        "model = models.resnet50(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 4)\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkRTjFcDwy7A",
        "outputId": "bc965c40-4b23-4a16-e0f7-4e9e1eb6b2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3: Define Loss and Optimizer"
      ],
      "metadata": {
        "id": "oMf1rkZWykgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', patience=2, factor=0.5\n",
        ")\n"
      ],
      "metadata": {
        "id": "9pf-dcbzyBJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4: Training and Validation Functions"
      ],
      "metadata": {
        "id": "MDH4_W5Cypal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "\n",
        "    for inputs, labels in tqdm(dataloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct_preds += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = correct_preds.double() / len(dataloader.dataset)\n",
        "    return epoch_loss, epoch_acc.item()\n",
        "\n",
        "\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct_preds += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = correct_preds.double() / len(dataloader.dataset)\n",
        "    return epoch_loss, epoch_acc.item()\n"
      ],
      "metadata": {
        "id": "aGYRP_AzyjHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 5: Run Training Loop"
      ],
      "metadata": {
        "id": "JU4Su6ZIywsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EPOCHS = 10\n",
        "\n",
        "# for epoch in range(EPOCHS):\n",
        "#     train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "#     val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
        "#     scheduler.step(val_loss)\n",
        "\n",
        "\n",
        "#     print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "#     print(f\"Train loss: {train_loss:.4f}, Train accuracy: {train_acc:.4f}\")\n",
        "#     print(f\"Val loss: {val_loss:.4f}, Val accuracy: {val_acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "!pip install -q timm\n",
        "\n",
        "import timm\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "model = timm.create_model('efficientnet_b3a', pretrained=True, num_classes=4)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', patience=2, factor=0.5\n",
        ")\n",
        "\n",
        "best_val_acc = 0\n",
        "patience, trigger = 3, 0\n",
        "\n",
        "EPOCHS = 20\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "    print(f\"Train loss: {train_loss:.4f}, acc: {train_acc:.4f}\")\n",
        "    print(f\"Val   loss: {val_loss:.4f}, acc: {val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        trigger = 0\n",
        "    else:\n",
        "        trigger += 1\n",
        "        if trigger >= patience:\n",
        "            print(\"Early stopping.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9w1NsGAyuL-",
        "outputId": "9a3b4220-f058-4c6c-8096-8aa933d44149"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name efficientnet_b3a to current efficientnet_b3.\n",
            "  model = create_fn(\n",
            "100%|██████████| 39/39 [00:21<00:00,  1.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Train loss: 0.7872, acc: 0.8093\n",
            "Val   loss: 0.1390, acc: 0.9469\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 39/39 [00:18<00:00,  2.13it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/20\n",
            "Train loss: 0.2129, acc: 0.9288\n",
            "Val   loss: 0.1533, acc: 0.9510\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 39/39 [00:19<00:00,  2.00it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/20\n",
            "Train loss: 0.1817, acc: 0.9394\n",
            "Val   loss: 0.1069, acc: 0.9633\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 39/39 [00:18<00:00,  2.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/20\n",
            "Train loss: 0.1298, acc: 0.9574\n",
            "Val   loss: 0.0568, acc: 0.9918\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 39/39 [00:19<00:00,  2.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/20\n",
            "Train loss: 0.1270, acc: 0.9632\n",
            "Val   loss: 0.1115, acc: 0.9592\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 39/39 [00:19<00:00,  1.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20\n",
            "Train loss: 0.1019, acc: 0.9673\n",
            "Val   loss: 0.0727, acc: 0.9714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:18<00:00,  2.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20\n",
            "Train loss: 0.0635, acc: 0.9779\n",
            "Val   loss: 0.0495, acc: 0.9837\n",
            "Early stopping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 6: Predict on Test Set and Prepare Submission\n"
      ],
      "metadata": {
        "id": "UnxVd5ICy8L6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.eval()\n",
        "# all_preds = []\n",
        "# all_img_ids = []\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for inputs, img_ids in test_loader:\n",
        "#         inputs = inputs.to(device)\n",
        "#         outputs = model(inputs)\n",
        "#         _, preds = torch.max(outputs, 1)\n",
        "#         all_preds.extend(preds.cpu().numpy())\n",
        "#         all_img_ids.extend(img_ids)\n",
        "\n",
        "\n",
        "from torchvision.transforms import functional as TF\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_img_ids = []\n",
        "\n",
        "tta_transforms = [\n",
        "    lambda x: x,\n",
        "    lambda x: TF.hflip(x),\n",
        "    lambda x: TF.vflip(x),\n",
        "    lambda x: TF.rotate(x, 15),\n",
        "]\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, img_ids in test_loader:\n",
        "        batch_preds = []\n",
        "        for tform in tta_transforms:\n",
        "            augmented = torch.stack([tform(img.cpu()) for img in inputs])\n",
        "            augmented = augmented.to(device)\n",
        "            outputs = model(augmented)\n",
        "            preds = torch.softmax(outputs, dim=1)\n",
        "            batch_preds.append(preds.cpu().numpy())\n",
        "        mean_preds = np.mean(batch_preds, axis=0)\n",
        "        final_preds = np.argmax(mean_preds, axis=1)\n",
        "        all_preds.extend(final_preds)\n",
        "        all_img_ids.extend(img_ids)\n",
        "\n",
        "# Reverse label_map to get soil_type string from label index\n",
        "inv_label_map = {v: k for k, v in label_map.items()}\n",
        "predicted_soil_types = [inv_label_map[p] for p in all_preds]\n",
        "\n",
        "import pandas as pd\n",
        "submission = pd.DataFrame({\n",
        "    \"image_id\": all_img_ids,\n",
        "    \"soil_type\": predicted_soil_types\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission5.csv\", index=False)\n",
        "print(\"Submission file created: submission5.csv\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "# model.eval()\n",
        "\n",
        "# tta_transforms = [\n",
        "#     transforms.Compose([\n",
        "#         transforms.Resize((224, 224)),\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize([0.485, 0.456, 0.406],\n",
        "#                              [0.229, 0.224, 0.225])\n",
        "#     ]),\n",
        "#     transforms.Compose([\n",
        "#         transforms.Resize((224, 224)),\n",
        "#         transforms.RandomHorizontalFlip(p=1.0),\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize([0.485, 0.456, 0.406],\n",
        "#                              [0.229, 0.224, 0.225])\n",
        "#     ])\n",
        "# ]\n",
        "\n",
        "# all_preds = []\n",
        "# all_img_ids = []\n",
        "\n",
        "# for tta_transform in tta_transforms:\n",
        "#     tta_dataset = SoilDataset(test_df, TEST_DIR, transform=tta_transform, test=True)\n",
        "#     tta_loader = DataLoader(tta_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "#     preds = []\n",
        "#     with torch.no_grad():\n",
        "#         for inputs, img_ids in tta_loader:\n",
        "#             inputs = inputs.to(device)\n",
        "#             outputs = model(inputs)\n",
        "#             preds.append(outputs.cpu())\n",
        "\n",
        "#     all_preds.append(torch.cat(preds))\n",
        "\n",
        "# final_outputs = sum(all_preds) / len(all_preds)\n",
        "# final_preds = torch.argmax(final_outputs, dim=1).numpy()\n",
        "# img_ids = test_df['image_id'].tolist()\n",
        "\n",
        "# # Map predictions\n",
        "# inv_label_map = {v: k for k, v in label_map.items()}\n",
        "# predicted_soil_types = [inv_label_map[p] for p in final_preds]\n",
        "\n",
        "# submission = pd.DataFrame({\n",
        "#     \"image_id\": img_ids,\n",
        "#     \"soil_type\": predicted_soil_types\n",
        "# })\n",
        "# submission.to_csv(\"submission4.csv\", index=False)\n",
        "# print(\"Created: submission4.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dQE12zOy1NL",
        "outputId": "f820e8eb-6eaf-4e96-9ca1-aa2e98b1f2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission5.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"submission5.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JfaUD8NLZG3W",
        "outputId": "107af67b-e8d5-4407-d1b7-b5e769b3aa6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8a9787b1-2f37-434d-a5a7-54c35e1181b1\", \"submission5.csv\", 9483)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}